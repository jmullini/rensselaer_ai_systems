{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a08abd2-a032-4586-b5c7-6f0439a3c1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 10:53:00.817396: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-01 10:53:00.817434: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from etl_resources import sqlite_connection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandasql as psql\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c766512b-bd3c-4475-9419-9a77e67f82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticker_list():\n",
    "    \n",
    "    con = sqlite_connection()\n",
    "    cur = con.cursor()\n",
    "    cur.execute('''\n",
    "    select distinct w.ticker from weekly_prices_clean w\n",
    "        inner join (select ticker from weekly_prices_clean\n",
    "        w\n",
    "        group by ticker\n",
    "        having max(date) > '2021-01-01') t on t.ticker=w.ticker\n",
    "        \n",
    "    ''')\n",
    "    res = cur.fetchall()\n",
    "    res = [val[0] for val in res]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db16f7c-7cc2-45dc-a229-f70e39459049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_df(ticker):\n",
    "    \n",
    "    '''\n",
    "    This function returns the base time series dataframe (date and close)\n",
    "    '''\n",
    "    \n",
    "    con = sqlite_connection()\n",
    "        \n",
    "    df = pd.read_sql(f'''select date,close \n",
    "    from weekly_prices_clean where ticker='{ticker}' --and date>'2017-12-31' \n",
    "    group by date,close\n",
    "    order by date asc''',con=con)\n",
    "    \n",
    "    df = df.filter(['close'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3483f05-aa3a-45e0-9f32-7f4bc3616ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_abs_perc_err(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd34416c-7cb6-4130-baef-4c54f5ca9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_change(x, y):\n",
    "    \n",
    "    x_array_length = len(x)\n",
    "    x_last_element = x[x_array_length - 1]\n",
    "    \n",
    "    y_array_length = len(y)\n",
    "    y_last_element = y[y_array_length - 1]\n",
    "    \n",
    "    return (y_last_element - x_last_element) / x_last_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805b9692-22a8-4da7-92a5-df1be4c74e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epochs, logs={}) :\n",
    "        threshold = 0.002\n",
    "        if(logs.get('loss') is not None and logs.get('loss') < threshold) :\n",
    "            print('\\nLoss dropped below {}, cancelling further training'.format(str(threshold)))\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a0d7f9-40a8-4d0c-be4f-dfa870195542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x_train, y_train, x_test, y_test, scaler):\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    callbacks = TFCallback()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, batch_size=1, epochs=15, callbacks=[callbacks])\n",
    "    \n",
    "    # Convert the data to a numpy array\n",
    "    x_test = np.array(x_test)\n",
    "\n",
    "    # Reshape the data\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "\n",
    "    # Get the models predicted price values \n",
    "    predictions = model.predict(x_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0116a494-199e-407d-8741-6c099f67fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for SPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 10:53:02.430075: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-01 10:53:02.430110: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-01 10:53:02.430131: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jameslaptop-Lenovo-Yoga-2-Pro): /proc/driver/nvidia/version does not exist\n",
      "2021-12-01 10:53:02.430396: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-01 10:53:02.920362: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 36s 33ms/step - loss: 0.0036\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 37s 35ms/step - loss: 0.0016\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " SPG : RMSE: 8.33 MAPE: 5.94 MSE: 69.4 MAE: 6.7\n",
      "Building model for SO\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 38s 35ms/step - loss: 0.0034\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " SO : RMSE: 1.51 MAPE: 1.89 MSE: 2.28 MAE: 1.18\n",
      "Building model for SBUX\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 38s 35ms/step - loss: 0.0036\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0013\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " SBUX : RMSE: 5.17 MAPE: 3.9 MSE: 26.75 MAE: 4.24\n",
      "Building model for TGT\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 38s 35ms/step - loss: 8.9224e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " TGT : RMSE: 16.38 MAPE: 6.78 MSE: 268.34 MAE: 14.25\n",
      "Building model for TXN\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 38s 35ms/step - loss: 0.0023\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 5.9728e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f97ec0754c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " TXN : RMSE: 5.39 MAPE: 2.4 MSE: 29.05 MAE: 4.3\n",
      "Building model for ALL\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 78s 73ms/step - loss: 0.0021\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 79s 77ms/step - loss: 0.0012\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f97cff6c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ALL : RMSE: 9.38 MAPE: 6.96 MSE: 87.96 MAE: 8.42\n",
      "Building model for BA\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 59s 56ms/step - loss: 0.0038\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 78s 76ms/step - loss: 0.0014\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " BA : RMSE: 22.81 MAPE: 8.3 MSE: 520.1 MAE: 18.57\n",
      "Building model for KO\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 78s 74ms/step - loss: 0.0069\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 78s 76ms/step - loss: 0.0038\n",
      "Epoch 3/15\n",
      "1032/1032 [==============================] - 77s 75ms/step - loss: 0.0034\n",
      "Epoch 4/15\n",
      "1032/1032 [==============================] - 77s 74ms/step - loss: 0.0027\n",
      "Epoch 5/15\n",
      "1032/1032 [==============================] - 77s 75ms/step - loss: 0.0028\n",
      "Epoch 6/15\n",
      "1032/1032 [==============================] - 77s 74ms/step - loss: 0.0037\n",
      "Epoch 7/15\n",
      "1032/1032 [==============================] - 77s 74ms/step - loss: 0.0027\n",
      "Epoch 8/15\n",
      "1032/1032 [==============================] - 77s 74ms/step - loss: 0.0026\n",
      "Epoch 9/15\n",
      "1032/1032 [==============================] - 77s 74ms/step - loss: 0.0024\n",
      "Epoch 10/15\n",
      "1032/1032 [==============================] - 77s 74ms/step - loss: 0.0026\n",
      "Epoch 11/15\n",
      "1032/1032 [==============================] - 77s 74ms/step - loss: 0.0031\n",
      "Epoch 12/15\n",
      "1032/1032 [==============================] - 76s 74ms/step - loss: 0.0026\n",
      "Epoch 13/15\n",
      "1032/1032 [==============================] - 76s 74ms/step - loss: 0.0024\n",
      "Epoch 14/15\n",
      "1032/1032 [==============================] - 76s 74ms/step - loss: 0.0024\n",
      "Epoch 15/15\n",
      "1032/1032 [==============================] - 38s 37ms/step - loss: 0.0021\n",
      "\n",
      " KO : RMSE: 1.23 MAPE: 1.75 MSE: 1.51 MAE: 0.92\n",
      "Building model for DOW\n",
      "Epoch 1/15\n",
      "72/72 [==============================] - 4s 34ms/step - loss: 0.0185\n",
      "Epoch 2/15\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.0082\n",
      "Epoch 3/15\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.0073\n",
      "Epoch 4/15\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.0072\n",
      "Epoch 5/15\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.0077\n",
      "Epoch 6/15\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.0060\n",
      "Epoch 7/15\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.0068\n",
      "Epoch 8/15\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.0068\n",
      "Epoch 9/15\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.0052\n",
      "Epoch 10/15\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.0079\n",
      "Epoch 11/15\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.0055\n",
      "Epoch 12/15\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.0095\n",
      "Epoch 13/15\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.0043\n",
      "Epoch 14/15\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.0073\n",
      "Epoch 15/15\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.0059\n",
      "\n",
      " DOW : RMSE: 3.08 MAPE: 4.99 MSE: 9.47 MAE: 2.91\n",
      "Building model for GS\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 41s 38ms/step - loss: 0.0021\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 38s 37ms/step - loss: 7.5044e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " GS : RMSE: 13.87 MAPE: 3.56 MSE: 192.43 MAE: 11.4\n",
      "Building model for KHC\n",
      "Epoch 1/15\n",
      "255/255 [==============================] - 11s 36ms/step - loss: 0.0092\n",
      "Epoch 2/15\n",
      "255/255 [==============================] - 10s 39ms/step - loss: 0.0034\n",
      "Epoch 3/15\n",
      "255/255 [==============================] - 9s 37ms/step - loss: 0.0036\n",
      "Epoch 4/15\n",
      "255/255 [==============================] - 10s 38ms/step - loss: 0.0025\n",
      "Epoch 5/15\n",
      "255/255 [==============================] - 11s 42ms/step - loss: 0.0032\n",
      "Epoch 6/15\n",
      "255/255 [==============================] - 9s 37ms/step - loss: 0.0025\n",
      "Epoch 7/15\n",
      "255/255 [==============================] - 9s 37ms/step - loss: 0.0020\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " KHC : RMSE: 2.08 MAPE: 5.44 MSE: 4.33 MAE: 2.0\n",
      "Building model for UNP\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 41s 37ms/step - loss: 0.0035\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 39s 37ms/step - loss: 0.0018\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " UNP : RMSE: 9.03 MAPE: 3.35 MSE: 81.61 MAE: 7.13\n",
      "Building model for UPS\n",
      "Epoch 1/15\n",
      "1031/1031 [==============================] - 39s 36ms/step - loss: 0.0016\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " UPS : RMSE: 10.7 MAPE: 4.37 MSE: 114.54 MAE: 8.28\n",
      "Building model for UTX\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 40s 37ms/step - loss: 0.0052\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 40s 38ms/step - loss: 0.0023\n",
      "Epoch 3/15\n",
      "1032/1032 [==============================] - 38s 37ms/step - loss: 0.0015\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " UTX : RMSE: 2.73 MAPE: 2.71 MSE: 7.43 MAE: 2.02\n",
      "Building model for UNH\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 39s 36ms/step - loss: 0.0015\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " UNH : RMSE: 39.74 MAPE: 9.34 MSE: 1579.47 MAE: 36.2\n",
      "Building model for USB\n",
      "Epoch 1/15\n",
      "1025/1025 [==============================] - 41s 38ms/step - loss: 0.0039\n",
      "Epoch 2/15\n",
      "1025/1025 [==============================] - 39s 38ms/step - loss: 0.0016\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " USB : RMSE: 2.44 MAPE: 3.7 MSE: 5.94 MAE: 1.86\n",
      "Building model for VZ\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 39s 36ms/step - loss: 0.0039\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 38s 37ms/step - loss: 0.0020\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " VZ : RMSE: 2.71 MAPE: 4.45 MSE: 7.34 MAE: 2.54\n",
      "Building model for V\n",
      "Epoch 1/15\n",
      "617/617 [==============================] - 25s 37ms/step - loss: 0.0102\n",
      "Epoch 2/15\n",
      "617/617 [==============================] - 23s 38ms/step - loss: 0.0057\n",
      "Epoch 3/15\n",
      "617/617 [==============================] - 23s 37ms/step - loss: 0.0040\n",
      "Epoch 4/15\n",
      "617/617 [==============================] - 23s 37ms/step - loss: 0.0038\n",
      "Epoch 5/15\n",
      "617/617 [==============================] - 23s 37ms/step - loss: 0.0032\n",
      "Epoch 6/15\n",
      "617/617 [==============================] - 23s 37ms/step - loss: 0.0028\n",
      "Epoch 7/15\n",
      "617/617 [==============================] - 23s 38ms/step - loss: 0.0031\n",
      "Epoch 8/15\n",
      "617/617 [==============================] - 23s 38ms/step - loss: 0.0027\n",
      "Epoch 9/15\n",
      "617/617 [==============================] - 23s 38ms/step - loss: 0.0027\n",
      "Epoch 10/15\n",
      "617/617 [==============================] - 23s 37ms/step - loss: 0.0027\n",
      "Epoch 11/15\n",
      "617/617 [==============================] - 24s 38ms/step - loss: 0.0028\n",
      "Epoch 12/15\n",
      "617/617 [==============================] - 24s 38ms/step - loss: 0.0024\n",
      "Epoch 13/15\n",
      "617/617 [==============================] - 23s 38ms/step - loss: 0.0028\n",
      "Epoch 14/15\n",
      "617/617 [==============================] - 23s 37ms/step - loss: 0.0026\n",
      "Epoch 15/15\n",
      "617/617 [==============================] - 23s 37ms/step - loss: 0.0030\n",
      "\n",
      " V : RMSE: 6.76 MAPE: 2.02 MSE: 45.67 MAE: 4.52\n",
      "Building model for WMT\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 40s 37ms/step - loss: 0.0018\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " WMT : RMSE: 40.93 MAPE: 28.55 MSE: 1674.97 MAE: 40.57\n",
      "Building model for WBA\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 41s 37ms/step - loss: 0.0042\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 39s 37ms/step - loss: 0.0021\n",
      "Epoch 3/15\n",
      "1032/1032 [==============================] - 38s 37ms/step - loss: 0.0014\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " WBA : RMSE: 2.67 MAPE: 4.08 MSE: 7.11 MAE: 1.93\n",
      "Building model for DIS\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 41s 38ms/step - loss: 0.0018\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " DIS : RMSE: 12.16 MAPE: 5.34 MSE: 147.84 MAE: 9.29\n",
      "Building model for WFC\n",
      "Epoch 1/15\n",
      "1032/1032 [==============================] - 41s 38ms/step - loss: 0.0055\n",
      "Epoch 2/15\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0027\n",
      "Epoch 3/15\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0018\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " WFC : RMSE: 2.78 MAPE: 6.23 MSE: 7.74 MAE: 2.38\n",
      "Building model for HON\n",
      "Epoch 1/15\n",
      "1031/1031 [==============================] - 34s 31ms/step - loss: 0.0018\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " HON : RMSE: 12.01 MAPE: 4.48 MSE: 144.15 MAE: 9.49\n",
      "Building model for NFLX\n",
      "Epoch 1/15\n",
      "905/905 [==============================] - 31s 32ms/step - loss: 0.0074\n",
      "Epoch 2/15\n",
      "905/905 [==============================] - 31s 34ms/step - loss: 0.0030\n",
      "Epoch 3/15\n",
      "905/905 [==============================] - 31s 34ms/step - loss: 0.0030\n",
      "Epoch 4/15\n",
      "905/905 [==============================] - 31s 34ms/step - loss: 0.0029\n",
      "Epoch 5/15\n",
      "905/905 [==============================] - 31s 34ms/step - loss: 0.0027\n",
      "Epoch 6/15\n",
      "905/905 [==============================] - 31s 34ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " NFLX : RMSE: 46.39 MAPE: 6.82 MSE: 2152.13 MAE: 38.6\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # following https://www.kaggle.com/faressayah/stock-market-analysis-prediction-using-lstm\n",
    "    tickers = ticker_list()\n",
    "    metrics_list = list()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        \n",
    "        print(f\"Building model for {ticker}\")\n",
    "        \n",
    "        metrics = dict()\n",
    "        \n",
    "        # Build the dataset and split\n",
    "        df = base_df(ticker)\n",
    "        dataset = df.values\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaled_data = scaler.fit_transform(dataset)\n",
    "        training_data_len = int(np.ceil( len(dataset) * .95 ))\n",
    "        train_data = scaled_data[0:int(training_data_len), :]\n",
    "    \n",
    "        # Split the data into x_train and y_train data sets\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        #print([i for i in range(100, len(train_data))])\n",
    "        for i in range(60, len(train_data)):\n",
    "            x_train.append(train_data[i-60:i, 0])\n",
    "            y_train.append(train_data[i, 0])\n",
    "       \n",
    "        x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "        x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "        test_data = scaled_data[training_data_len - 60: , :]\n",
    "        \n",
    "        # Create the data sets x_test and y_test\n",
    "        x_test = []\n",
    "        y_test = dataset[training_data_len:, :]\n",
    "        for i in range(60, len(test_data)):\n",
    "            x_test.append(test_data[i-60:i, 0])\n",
    "    \n",
    "        # Convert the data to a numpy array\n",
    "        x_test = np.array(x_test)\n",
    "\n",
    "        # Reshape the data\n",
    "        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "        \n",
    "        # Train & Test LSTM\n",
    "        predictions = build_lstm(x_train, y_train, x_test, y_test, scaler)\n",
    "        \n",
    "        train = df[:training_data_len]\n",
    "        valid = df[training_data_len:]\n",
    "        valid['Predictions'] = predictions\n",
    "        \n",
    "        metrics['ticker'] = ticker\n",
    "        \n",
    "        rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
    "        mape = mean_abs_perc_err(y_test, predictions)\n",
    "        mse = mean_squared_error(y_true = y_test, y_pred = predictions)\n",
    "        mae = mean_absolute_error(y_true = y_test, y_pred = predictions)\n",
    "        #yhat_perc_change = perc_change(x_train, predictions)\n",
    "        #y_perc_change = perc_change(x_train, valid)\n",
    "\n",
    "        metrics['RMSE'] = rmse\n",
    "        metrics['MAPE'] = mape\n",
    "        metrics['MSE'] = mse\n",
    "        metrics['MAE'] = mae\n",
    "        #metrics['yhat_perc_change'] = yhat_perc_change\n",
    "        #metrics['y_perc_change'] = y_perc_change\n",
    "        \n",
    "        metrics_list.append(metrics)\n",
    "        \n",
    "        print('\\n',ticker,': RMSE:',round(rmse,2),'MAPE:',round(mape,2),'MSE:',round(mse,2),'MAE:',round(mae,2))\n",
    "                                             \n",
    "        # Visualize the data\n",
    "        plt.figure(figsize=(16,6))\n",
    "        plt.title('Model')\n",
    "        plt.xlabel('Date', fontsize=18)\n",
    "        plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "        plt.plot(train['close'])\n",
    "        plt.plot(valid[['close', 'Predictions']])\n",
    "        plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "        plt.savefig(f'../data/visualization/lstm/{ticker}.png', facecolor='white', transparent=False)\n",
    "        plt.close('all')\n",
    "    \n",
    "        total_metrics = pd.DataFrame(metrics_list)\n",
    "        total_metrics.to_csv('forecast_metrics_lstm.csv')\n",
    "\n",
    "main()      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
