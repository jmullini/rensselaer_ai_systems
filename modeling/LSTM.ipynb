{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a08abd2-a032-4586-b5c7-6f0439a3c1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 22:07:47.317086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-30 22:07:47.317122: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from etl_resources import sqlite_connection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandasql as psql\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c766512b-bd3c-4475-9419-9a77e67f82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticker_list():\n",
    "    \n",
    "    con = sqlite_connection()\n",
    "    cur = con.cursor()\n",
    "    cur.execute('''\n",
    "    select distinct w.ticker from weekly_prices_clean w\n",
    "        inner join (select ticker from weekly_prices_clean\n",
    "        group by ticker\n",
    "        having max(date) > '2021-01-01') t on t.ticker=w.ticker\n",
    "        \n",
    "    ''')\n",
    "    res = cur.fetchall()\n",
    "    res = [val[0] for val in res]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db16f7c-7cc2-45dc-a229-f70e39459049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_df(ticker):\n",
    "    \n",
    "    '''\n",
    "    This function returns the base time series dataframe (date and close)\n",
    "    '''\n",
    "    \n",
    "    con = sqlite_connection()\n",
    "        \n",
    "    df = pd.read_sql(f'''select date,close \n",
    "    from weekly_prices_clean where ticker='{ticker}' --and date>'2017-12-31' \n",
    "    group by date,close\n",
    "    order by date asc''',con=con)\n",
    "    \n",
    "    df = df.filter(['close'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3483f05-aa3a-45e0-9f32-7f4bc3616ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_abs_perc_err(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd34416c-7cb6-4130-baef-4c54f5ca9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_change(x, y):\n",
    "    \n",
    "    x_array_length = len(x)\n",
    "    x_last_element = x[x_array_length - 1]\n",
    "    \n",
    "    y_array_length = len(y)\n",
    "    y_last_element = y[y_array_length - 1]\n",
    "    \n",
    "    return (y_last_element - x_last_element) / x_last_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805b9692-22a8-4da7-92a5-df1be4c74e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epochs, logs={}) :\n",
    "        threshold = 0.002\n",
    "        if(logs.get('loss') is not None and logs.get('loss') < threshold) :\n",
    "            print('\\nLoss dropped below {}, cancelling further training'.format(str(threshold)))\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a0d7f9-40a8-4d0c-be4f-dfa870195542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x_train, y_train, x_test, y_test, scaler):\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    callbacks = TFCallback()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, batch_size=1, epochs=50, callbacks=[callbacks])\n",
    "    \n",
    "    # Convert the data to a numpy array\n",
    "    x_test = np.array(x_test)\n",
    "\n",
    "    # Reshape the data\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "\n",
    "    # Get the models predicted price values \n",
    "    predictions = model.predict(x_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116a494-199e-407d-8741-6c099f67fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for MMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 22:07:48.903113: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-30 22:07:48.903153: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-30 22:07:48.903185: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jameslaptop-Lenovo-Yoga-2-Pro): /proc/driver/nvidia/version does not exist\n",
      "2021-11-30 22:07:48.903491: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-30 22:07:49.390673: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 37s 34ms/step - loss: 0.0025\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0011\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " MMM : RMSE: 6.39 MAPE: 2.82 MSE: 40.81 MAE: 5.12\n",
      "Building model for BKNG\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 41s 38ms/step - loss: 0.0029\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 38s 37ms/step - loss: 0.0015\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " BKNG : RMSE: 112.18 MAPE: 4.22 MSE: 12584.42 MAE: 92.62\n",
      "Building model for ABT\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 41s 37ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " ABT : RMSE: 6.98 MAPE: 5.06 MSE: 48.66 MAE: 5.89\n",
      "Building model for ABBV\n",
      "Epoch 1/50\n",
      "379/379 [==============================] - 15s 36ms/step - loss: 0.0101\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 14s 38ms/step - loss: 0.0048\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 14s 37ms/step - loss: 0.0040\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 14s 37ms/step - loss: 0.0031\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 15s 40ms/step - loss: 0.0027\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 14s 37ms/step - loss: 0.0025\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 14s 37ms/step - loss: 0.0023\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 14s 37ms/step - loss: 0.0020\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 14s 37ms/step - loss: 0.0021\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 14s 38ms/step - loss: 0.0025\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 14s 38ms/step - loss: 0.0020\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 14s 37ms/step - loss: 0.0023\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 14s 38ms/step - loss: 0.0021\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 15s 39ms/step - loss: 0.0021\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 14s 38ms/step - loss: 0.0021\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 14s 38ms/step - loss: 0.0018\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " ABBV : RMSE: 4.43 MAPE: 3.51 MSE: 19.66 MAE: 4.02\n",
      "Building model for ACN\n",
      "Epoch 1/50\n",
      "947/947 [==============================] - 38s 38ms/step - loss: 0.0013\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1446ee64c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ACN : RMSE: 20.63 MAPE: 6.26 MSE: 425.56 MAE: 17.71\n",
      "Building model for ADBE\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 42s 39ms/step - loss: 0.0012\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f144629cf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ADBE : RMSE: 34.47 MAPE: 5.13 MSE: 1187.85 MAE: 28.27\n",
      "Building model for MO\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 41s 38ms/step - loss: 0.0063\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 40s 38ms/step - loss: 0.0024\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 40s 38ms/step - loss: 0.0020\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " MO : RMSE: 2.02 MAPE: 3.64 MSE: 4.08 MAE: 1.68\n",
      "Building model for AMZN\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 42s 38ms/step - loss: 0.0014\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " AMZN : RMSE: 154.8 MAPE: 3.63 MSE: 23963.35 MAE: 122.02\n",
      "Building model for AXP\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 41s 38ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " AXP : RMSE: 7.32 MAPE: 4.17 MSE: 53.52 MAE: 5.87\n",
      "Building model for AIG\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 41s 38ms/step - loss: 0.0020\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 9.7048e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " AIG : RMSE: 2.3 MAPE: 4.02 MSE: 5.3 MAE: 1.84\n",
      "Building model for AMGN\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 42s 38ms/step - loss: 0.0035\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0016\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " AMGN : RMSE: 10.83 MAPE: 3.53 MSE: 117.19 MAE: 8.45\n",
      "Building model for AAPL\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 42s 38ms/step - loss: 0.0054\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 40s 39ms/step - loss: 0.0030\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0028\n",
      "Epoch 4/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0026\n",
      "Epoch 5/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0021\n",
      "Epoch 6/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " AAPL : RMSE: 4.31 MAPE: 2.58 MSE: 18.54 MAE: 3.37\n",
      "Building model for T\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 37s 34ms/step - loss: 0.0035\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0015\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " T : RMSE: 0.72 MAPE: 1.85 MSE: 0.52 MAE: 0.54\n",
      "Building model for BAC\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 39s 36ms/step - loss: 0.0045\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " BAC : RMSE: 5.16 MAPE: 13.77 MSE: 26.67 MAE: 4.86\n",
      "Building model for BK\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 41s 38ms/step - loss: 0.0045\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0024\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " BK : RMSE: 1.73 MAPE: 2.96 MSE: 3.0 MAE: 1.41\n",
      "Building model for BRK.B\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 42s 38ms/step - loss: 0.0040\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0017\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " BRK.B : RMSE: 42.14 MAPE: 16.12 MSE: 1775.83 MAE: 41.57\n",
      "Building model for BIIB\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 40s 37ms/step - loss: 0.0033 1s\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 40s 38ms/step - loss: 0.0016\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " BIIB : RMSE: 23.7 MAPE: 4.75 MSE: 561.52 MAE: 14.43\n",
      "Building model for BLK\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 42s 38ms/step - loss: 0.0013\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " BLK : RMSE: 49.53 MAPE: 5.24 MSE: 2453.33 MAE: 42.29\n",
      "Building model for BMY\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 41s 38ms/step - loss: 0.0042\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 0.0021\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 40s 39ms/step - loss: 0.0015\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " BMY : RMSE: 1.76 MAPE: 2.12 MSE: 3.1 MAE: 1.34\n",
      "Building model for COF\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 38s 34ms/step - loss: 0.0021\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 39s 38ms/step - loss: 9.2713e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " COF : RMSE: 6.61 MAPE: 3.87 MSE: 43.65 MAE: 5.06\n",
      "Building model for CAT\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 39s 36ms/step - loss: 0.0020\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " CAT : RMSE: 13.45 MAPE: 5.43 MSE: 180.86 MAE: 11.16\n",
      "Building model for CHTR\n",
      "Epoch 1/50\n",
      "528/528 [==============================] - 20s 34ms/step - loss: 0.0023\n",
      "Epoch 2/50\n",
      "528/528 [==============================] - 19s 35ms/step - loss: 9.9533e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " CHTR : RMSE: 41.17 MAPE: 4.84 MSE: 1694.73 MAE: 35.47\n",
      "Building model for CVX\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 38s 35ms/step - loss: 0.0085\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0034\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0026\n",
      "Epoch 4/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0026\n",
      "Epoch 5/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0024\n",
      "Epoch 6/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0022\n",
      "Epoch 7/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0024\n",
      "Epoch 8/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0022\n",
      "Epoch 9/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0024\n",
      "Epoch 10/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0022\n",
      "Epoch 11/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0022\n",
      "Epoch 12/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0022\n",
      "Epoch 13/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0022\n",
      "Epoch 14/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0022\n",
      "Epoch 15/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0022\n",
      "Epoch 16/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0022\n",
      "Epoch 17/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0021\n",
      "Epoch 18/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0021\n",
      "Epoch 19/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0022\n",
      "Epoch 20/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0022\n",
      "Epoch 21/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0021\n",
      "Epoch 22/50\n",
      "1032/1032 [==============================] - 37s 35ms/step - loss: 0.0021\n",
      "Epoch 23/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0020\n",
      "Epoch 24/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0020\n",
      "Epoch 25/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0020\n",
      "Epoch 26/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0021\n",
      "Epoch 27/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0020\n",
      "Epoch 28/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0021\n",
      "Epoch 29/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0021\n",
      "Epoch 30/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0020\n",
      "Epoch 31/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0021\n",
      "Epoch 32/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0020\n",
      "Epoch 33/50\n",
      "1032/1032 [==============================] - 41s 40ms/step - loss: 0.0021\n",
      "Epoch 34/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0021\n",
      "Epoch 35/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " CVX : RMSE: 4.31 MAPE: 3.48 MSE: 18.61 MAE: 3.4\n",
      "Building model for CSCO\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 39s 35ms/step - loss: 6.9777e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " CSCO : RMSE: 3.05 MAPE: 5.16 MSE: 9.32 MAE: 2.59\n",
      "Building model for C\n",
      "Epoch 1/50\n",
      "1025/1025 [==============================] - 37s 34ms/step - loss: 0.0045\n",
      "Epoch 2/50\n",
      "1025/1025 [==============================] - 37s 36ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " C : RMSE: 6.31 MAPE: 8.91 MSE: 39.88 MAE: 5.78\n",
      "Building model for CL\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 36s 33ms/step - loss: 0.0060\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0031\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0025\n",
      "Epoch 4/50\n",
      "1032/1032 [==============================] - 37s 35ms/step - loss: 0.0022\n",
      "Epoch 5/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0023\n",
      "Epoch 6/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0020\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " CL : RMSE: 1.72 MAPE: 1.67 MSE: 2.95 MAE: 1.35\n",
      "Building model for CMCSA\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 34s 31ms/step - loss: 0.0043\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 34s 33ms/step - loss: 0.0020\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 0.0021\n",
      "Epoch 4/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 0.0015\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " CMCSA : RMSE: 1.87 MAPE: 2.77 MSE: 3.48 MAE: 1.49\n",
      "Building model for COP\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 37s 34ms/step - loss: 0.0049\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 0.0026\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 0.0022\n",
      "Epoch 4/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 0.0026\n",
      "Epoch 5/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " COP : RMSE: 2.91 MAPE: 4.78 MSE: 8.49 MAE: 2.34\n",
      "Building model for COST\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 37s 34ms/step - loss: 9.2582e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " COST : RMSE: 22.93 MAPE: 4.72 MSE: 525.81 MAE: 18.97\n",
      "Building model for CVS\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 36s 33ms/step - loss: 0.0036\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0017\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " CVS : RMSE: 4.76 MAPE: 4.94 MSE: 22.68 MAE: 3.91\n",
      "Building model for DHR\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 36s 33ms/step - loss: 0.0013\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " DHR : RMSE: 27.5 MAPE: 8.52 MSE: 755.98 MAE: 22.01\n",
      "Building model for DUK\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 37s 34ms/step - loss: 0.0050\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0024\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0015\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " DUK : RMSE: 2.16 MAPE: 1.75 MSE: 4.67 MAE: 1.67\n",
      "Building model for LLY\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 34s 31ms/step - loss: 8.1239e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " LLY : RMSE: 31.24 MAPE: 13.16 MSE: 976.21 MAE: 27.79\n",
      "Building model for EMR\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 37s 34ms/step - loss: 0.0041\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0020\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " EMR : RMSE: 3.41 MAPE: 3.27 MSE: 11.6 MAE: 2.95\n",
      "Building model for EXC\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 36s 33ms/step - loss: 0.0059\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0025\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0020\n",
      "Epoch 4/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0017\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " EXC : RMSE: 1.97 MAPE: 3.75 MSE: 3.89 MAE: 1.7\n",
      "Building model for XOM\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 38s 35ms/step - loss: 0.0058\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0027\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0022\n",
      "Epoch 4/50\n",
      "1032/1032 [==============================] - 38s 37ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " XOM : RMSE: 2.36 MAPE: 3.54 MSE: 5.55 MAE: 1.83\n",
      "Building model for FB\n",
      "Epoch 1/50\n",
      "411/411 [==============================] - 17s 36ms/step - loss: 0.0040\n",
      "Epoch 2/50\n",
      "411/411 [==============================] - 14s 35ms/step - loss: 0.0020\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " FB : RMSE: 23.61 MAPE: 5.21 MSE: 557.66 MAE: 17.73\n",
      "Building model for FDX\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 36s 33ms/step - loss: 0.0024\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0010\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " FDX : RMSE: 12.61 MAPE: 3.69 MSE: 159.07 MAE: 10.07\n",
      "Building model for F\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 39s 35ms/step - loss: 8.4546e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " F : RMSE: 2.2 MAPE: 14.67 MSE: 4.85 MAE: 1.91\n",
      "Building model for GD\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 39s 35ms/step - loss: 0.0049\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0016\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " GD : RMSE: 6.05 MAPE: 2.84 MSE: 36.66 MAE: 4.99\n",
      "Building model for GE\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 39s 35ms/step - loss: 3.6142e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " GE : RMSE: 18.47 MAPE: 10.71 MSE: 341.15 MAE: 6.96\n",
      "Building model for GM\n",
      "Epoch 1/50\n",
      "485/485 [==============================] - 19s 34ms/step - loss: 0.0070\n",
      "Epoch 2/50\n",
      "485/485 [==============================] - 17s 36ms/step - loss: 0.0029\n",
      "Epoch 3/50\n",
      "485/485 [==============================] - 17s 35ms/step - loss: 0.0024\n",
      "Epoch 4/50\n",
      "485/485 [==============================] - 17s 36ms/step - loss: 0.0019\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " GM : RMSE: 2.8 MAPE: 4.0 MSE: 7.86 MAE: 2.24\n",
      "Building model for GILD\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 39s 35ms/step - loss: 0.0056\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0030\n",
      "Epoch 3/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0026\n",
      "Epoch 4/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0027\n",
      "Epoch 5/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0023\n",
      "Epoch 6/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0024\n",
      "Epoch 7/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0024\n",
      "Epoch 8/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0023\n",
      "Epoch 9/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0023\n",
      "Epoch 10/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0023\n",
      "Epoch 11/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0022\n",
      "Epoch 12/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0023\n",
      "Epoch 13/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0022\n",
      "Epoch 14/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0022\n",
      "Epoch 15/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0023\n",
      "Epoch 16/50\n",
      "1032/1032 [==============================] - 37s 35ms/step - loss: 0.0022\n",
      "Epoch 17/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0022\n",
      "Epoch 18/50\n",
      "1032/1032 [==============================] - 37s 35ms/step - loss: 0.0022\n",
      "Epoch 19/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0021\n",
      "Epoch 20/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0022\n",
      "Epoch 21/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0021\n",
      "Epoch 22/50\n",
      "1032/1032 [==============================] - 36s 35ms/step - loss: 0.0020\n",
      "Epoch 23/50\n",
      "1032/1032 [==============================] - 38s 36ms/step - loss: 0.0021\n",
      "Epoch 24/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0020\n",
      "Epoch 25/50\n",
      "1032/1032 [==============================] - 37s 36ms/step - loss: 0.0020\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " GILD : RMSE: 1.88 MAPE: 2.35 MSE: 3.55 MAE: 1.52\n",
      "Building model for GOOG\n",
      "Epoch 1/50\n",
      "319/319 [==============================] - 12s 30ms/step - loss: 0.0028\n",
      "Epoch 2/50\n",
      "319/319 [==============================] - 10s 30ms/step - loss: 0.0021\n",
      "Epoch 3/50\n",
      "319/319 [==============================] - 10s 31ms/step - loss: 0.0017\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " GOOG : RMSE: 85.14 MAPE: 2.68 MSE: 7248.0 MAE: 74.9\n",
      "Building model for GOOGL\n",
      "Epoch 1/50\n",
      "795/795 [==============================] - 27s 32ms/step - loss: 0.0014\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " GOOGL : RMSE: 90.58 MAPE: 3.09 MSE: 8203.92 MAE: 73.81\n",
      "Building model for HD\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 35s 32ms/step - loss: 0.0014\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " HD : RMSE: 21.02 MAPE: 6.36 MSE: 442.05 MAE: 18.75\n",
      "Building model for INTC\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 37s 34ms/step - loss: 6.8690e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " INTC : RMSE: 4.81 MAPE: 7.23 MSE: 23.12 MAE: 4.06\n",
      "Building model for IBM\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 38s 35ms/step - loss: 0.0041\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 0.0020\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " IBM : RMSE: 5.55 MAPE: 3.14 MSE: 30.79 MAE: 4.01\n",
      "Building model for JNJ\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 38s 34ms/step - loss: 0.0030\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 0.0014\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " JNJ : RMSE: 5.08 MAPE: 2.67 MSE: 25.77 MAE: 4.34\n",
      "Building model for JPM\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 36s 33ms/step - loss: 0.0023\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 9.6618e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " JPM : RMSE: 8.3 MAPE: 4.97 MSE: 68.92 MAE: 7.32\n",
      "Building model for KMI\n",
      "Epoch 1/50\n",
      "473/473 [==============================] - 19s 34ms/step - loss: 0.0075\n",
      "Epoch 2/50\n",
      "473/473 [==============================] - 16s 34ms/step - loss: 0.0030\n",
      "Epoch 3/50\n",
      "473/473 [==============================] - 16s 34ms/step - loss: 0.0021\n",
      "Epoch 4/50\n",
      "473/473 [==============================] - 16s 34ms/step - loss: 0.0023\n",
      "Epoch 5/50\n",
      "473/473 [==============================] - 16s 34ms/step - loss: 0.0022\n",
      "Epoch 6/50\n",
      "473/473 [==============================] - 16s 34ms/step - loss: 0.0018\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " KMI : RMSE: 0.66 MAPE: 2.99 MSE: 0.43 MAE: 0.52\n",
      "Building model for LMT\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 34s 31ms/step - loss: 0.0024\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 0.0013\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " LMT : RMSE: 18.26 MAPE: 4.41 MSE: 333.54 MAE: 15.63\n",
      "Building model for LOW\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 35s 32ms/step - loss: 0.0013\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " LOW : RMSE: 13.77 MAPE: 6.32 MSE: 189.55 MAE: 11.48\n",
      "Building model for MA\n",
      "Epoch 1/50\n",
      "707/707 [==============================] - 27s 34ms/step - loss: 0.0096\n",
      "Epoch 2/50\n",
      "707/707 [==============================] - 24s 35ms/step - loss: 0.0060\n",
      "Epoch 3/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0035\n",
      "Epoch 4/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0031\n",
      "Epoch 5/50\n",
      "707/707 [==============================] - 24s 35ms/step - loss: 0.0023\n",
      "Epoch 6/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0035\n",
      "Epoch 7/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0034\n",
      "Epoch 8/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0024\n",
      "Epoch 9/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0030\n",
      "Epoch 10/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0030\n",
      "Epoch 11/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0027\n",
      "Epoch 12/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0028\n",
      "Epoch 13/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0025\n",
      "Epoch 14/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0031\n",
      "Epoch 15/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0024\n",
      "Epoch 16/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0025\n",
      "Epoch 17/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0023\n",
      "Epoch 18/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0024\n",
      "Epoch 19/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0021\n",
      "Epoch 20/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0022\n",
      "Epoch 21/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0025\n",
      "Epoch 22/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0025\n",
      "Epoch 23/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0021\n",
      "Epoch 24/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0022\n",
      "Epoch 25/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0024\n",
      "Epoch 26/50\n",
      "707/707 [==============================] - 24s 34ms/step - loss: 0.0020\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " MA : RMSE: 16.17 MAPE: 3.78 MSE: 261.32 MAE: 13.61\n",
      "Building model for MCD\n",
      "Epoch 1/50\n",
      "1032/1032 [==============================] - 37s 34ms/step - loss: 0.0021\n",
      "Epoch 2/50\n",
      "1032/1032 [==============================] - 35s 34ms/step - loss: 7.0064e-04\n",
      "\n",
      "Loss dropped below 0.002, cancelling further training\n",
      "\n",
      " MCD : RMSE: 5.64 MAPE: 2.08 MSE: 31.75 MAE: 4.65\n",
      "Building model for MDT\n",
      "Epoch 1/50\n",
      " 795/1032 [======================>.......] - ETA: 7s - loss: 0.0026"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # following https://www.kaggle.com/faressayah/stock-market-analysis-prediction-using-lstm\n",
    "    tickers = ticker_list()\n",
    "    metrics_list = list()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        \n",
    "        print(f\"Building model for {ticker}\")\n",
    "        \n",
    "        metrics = dict()\n",
    "        \n",
    "        # Build the dataset and split\n",
    "        df = base_df(ticker)\n",
    "        dataset = df.values\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaled_data = scaler.fit_transform(dataset)\n",
    "        training_data_len = int(np.ceil( len(dataset) * .95 ))\n",
    "        train_data = scaled_data[0:int(training_data_len), :]\n",
    "    \n",
    "        # Split the data into x_train and y_train data sets\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        #print([i for i in range(100, len(train_data))])\n",
    "        for i in range(60, len(train_data)):\n",
    "            x_train.append(train_data[i-60:i, 0])\n",
    "            y_train.append(train_data[i, 0])\n",
    "       \n",
    "        x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "        x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "        test_data = scaled_data[training_data_len - 60: , :]\n",
    "        \n",
    "        # Create the data sets x_test and y_test\n",
    "        x_test = []\n",
    "        y_test = dataset[training_data_len:, :]\n",
    "        for i in range(60, len(test_data)):\n",
    "            x_test.append(test_data[i-60:i, 0])\n",
    "    \n",
    "        # Convert the data to a numpy array\n",
    "        x_test = np.array(x_test)\n",
    "\n",
    "        # Reshape the data\n",
    "        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "        \n",
    "        # Train & Test LSTM\n",
    "        predictions = build_lstm(x_train, y_train, x_test, y_test, scaler)\n",
    "        \n",
    "        train = df[:training_data_len]\n",
    "        valid = df[training_data_len:]\n",
    "        valid['Predictions'] = predictions\n",
    "        \n",
    "        metrics['ticker'] = ticker\n",
    "        \n",
    "        rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
    "        mape = mean_abs_perc_err(y_test, predictions)\n",
    "        mse = mean_squared_error(y_true = y_test, y_pred = predictions)\n",
    "        mae = mean_absolute_error(y_true = y_test, y_pred = predictions)\n",
    "        #yhat_perc_change = perc_change(x_train, predictions)\n",
    "        #y_perc_change = perc_change(x_train, valid)\n",
    "\n",
    "        metrics['RMSE'] = rmse\n",
    "        metrics['MAPE'] = mape\n",
    "        metrics['MSE'] = mse\n",
    "        metrics['MAE'] = mae\n",
    "        #metrics['yhat_perc_change'] = yhat_perc_change\n",
    "        #metrics['y_perc_change'] = y_perc_change\n",
    "        \n",
    "        metrics_list.append(metrics)\n",
    "        \n",
    "        print('\\n',ticker,': RMSE:',round(rmse,2),'MAPE:',round(mape,2),'MSE:',round(mse,2),'MAE:',round(mae,2))\n",
    "                                             \n",
    "        # Visualize the data\n",
    "        plt.figure(figsize=(16,6))\n",
    "        plt.title('Model')\n",
    "        plt.xlabel('Date', fontsize=18)\n",
    "        plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "        plt.plot(train['close'])\n",
    "        plt.plot(valid[['close', 'Predictions']])\n",
    "        plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "        plt.savefig(f'../data/visualization/lstm/{ticker}.png', facecolor='white', transparent=False)\n",
    "        plt.close('all')\n",
    "    \n",
    "    total_metrics = pd.DataFrame(metrics_list)\n",
    "    total_metrics.to_csv('forecast_metrics_lstm.csv')\n",
    "\n",
    "main()      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
